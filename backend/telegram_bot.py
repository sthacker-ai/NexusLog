
import os
import re
import time
import json
import logging
import asyncio
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from models import Entry, ContentIdea, Category, get_session
from ai_services import AIServiceManager
from category_manager import CategoryManager
from sheets_integration import SheetsIntegration
from content_extractor import get_content_extractor
from file_storage import storage  # Import our new storage abstraction
from typing import Dict, List, Optional, Any
from dotenv import load_dotenv

# ... (Logging setup remains same) ...
# Load environment variables
load_dotenv()

# Configure Logging - both console and file output
# Configure Logging - both console and file output
log_handlers = [logging.StreamHandler()]  # Console output always

try:
    os.makedirs('logs', exist_ok=True)
    log_handlers.append(logging.FileHandler('logs/bot.log', mode='a', encoding='utf-8'))
except OSError:
    pass  # Read-only filesystem (Vercel)

log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
logging.basicConfig(
    level=logging.INFO,
    format=log_format,
    handlers=log_handlers
)
logger = logging.getLogger(__name__)

# ... (Env loading remains same) ...
# Load environment variables robustly
from config import get_env

# ... (Logging setup remains same) ...

class TelegramBot:
    """Telegram bot for NexusLog"""
    
    def __init__(self):
        self.token = get_env('TELEGRAM_BOT_TOKEN')
        if not self.token:
            raise ValueError("TELEGRAM_BOT_TOKEN not set")
        
        self.ai_manager = AIServiceManager()
        self.category_manager = CategoryManager()
        
        try:
            self.sheets = SheetsIntegration()
        except Exception as e:
            logger.error(f"Failed to initialize Google Sheets: {e}")
            self.sheets = None
            
        self.application = Application.builder().token(self.token).build()
        self._setup_handlers()

    # ... (Handlers setup remains same) ...
    def _setup_handlers(self):
        """Register all command and message handlers"""
        self.application.add_handler(CommandHandler("start", self.start))
        self.application.add_handler(CommandHandler("help", self.help))
        self.application.add_handler(CommandHandler("categories", self.list_categories))
        
        # Handle different content types
        # Note: We wrap handlers in run_in_executor in the handle methods themselves
        self.application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_text))
        self.application.add_handler(MessageHandler(filters.PHOTO, self.handle_image))
        self.application.add_handler(MessageHandler(filters.VOICE | filters.AUDIO, self.handle_audio))
        self.application.add_handler(MessageHandler(filters.VIDEO, self.handle_video))
        self.application.add_handler(MessageHandler(filters.ANIMATION, self.handle_animation))
        
        # Error handler
        self.application.add_error_handler(self.error_handler)

    # ... (start, help, list_categories remain same) ...
    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        await update.message.reply_text(
            "üëã Welcome to NexusLog Bot!\n\n"
            "I can help you log ideas, reading lists, and content.\n"
            "Just send me text, voice notes, images, or links.\n\n"
            "Commands:\n"
            "/categories - List available categories\n"
            "/help - Show usage instructions"
        )

    async def help(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        await update.message.reply_text(
            "üìù *NexusLog Usage*\n\n"
            "*Text*: Just type your thought\n"
            "*Voice*: Record a voice note (I'll transcribe it)\n"
            "*Image*: Send a photo (I'll analyze it)\n"
            "*Link*: Share a URL (I'll extract content)\n\n"
            "_Tips:_\n"
            "- Start with 'Journal:' for trading journal\n"
            "- Mention 'blog', 'video', 'linkedin' to flag as content idea",
            parse_mode='Markdown'
        )

    async def list_categories(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        categories = self.category_manager.get_all_categories()
        
        if not categories:
            await update.message.reply_text("No categories found.")
            return

        text = "üìÇ *Categories*\n\n"
        for cat in categories:
            text += f"‚Ä¢ *{cat['name']}*\n"
            if cat.get('subcategories'):
                for sub in cat['subcategories']:
                    text += f"  - {sub['name']}\n"
        
        await update.message.reply_text(text, parse_mode='Markdown')

    async def error_handler(self, update: object, context: ContextTypes.DEFAULT_TYPE):
        logger.error(f"Exception while handling an update: {context.error}")

    # ... (Wait, I need to update the file handling methods to use storage.save_file) ...
    
    async def handle_image(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle incoming images"""
        await self._run_async(self._handle_image_impl, update, context)

    def _handle_image_impl(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        try:
            # Send initial processing message
            message = asyncio.run(update.message.reply_text("üñºÔ∏è Processing image..."))
            
            # Get the largest photo
            photo = update.message.photo[-1]
            file = asyncio.run(context.bot.get_file(photo.file_id))
            
            # Download file to memory
            from io import BytesIO
            f = BytesIO()
            asyncio.run(file.download_to_memory(f))
            file_data = f.getvalue()
            
            # Generate filename
            timestamp = int(time.time())
            filename = f"images/{timestamp}_{photo.file_id}.jpg"
            
            # Save using storage abstraction
            file_path = storage.save_file(file_data, filename, content_type='image/jpeg')
            
            # Process with AI
            analysis = self.ai_manager.analyze_image(file_data)
            
            # Store in DB
            self._process_and_store(
                update, 
                content=analysis, 
                content_type='image',
                file_path=file_path,
                reply_message=message
            )
            
        except Exception as e:
            logger.error(f"Error handling image: {e}")
            if 'message' in locals():
                asyncio.run(message.edit_text(f"‚ùå Error processing image: {str(e)}"))

    async def handle_audio(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle voice notes and audio files"""
        await self._run_async(self._handle_audio_impl, update, context)

    def _handle_audio_impl(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        try:
            message = asyncio.run(update.message.reply_text("üé§ Processing audio..."))
            
            # Get audio file
            audio = update.message.voice or update.message.audio
            file = asyncio.run(context.bot.get_file(audio.file_id))
            
            # Download
            from io import BytesIO
            f = BytesIO()
            asyncio.run(file.download_to_memory(f))
            file_data = f.getvalue()
            
            # Determine extension
            mime_type = getattr(audio, 'mime_type', 'audio/ogg')
            ext = '.ogg'
            if mime_type == 'audio/mpeg': ext = '.mp3'
            elif mime_type == 'audio/wav': ext = '.wav'
            
            # Save
            timestamp = int(time.time())
            filename = f"audio/{timestamp}_{audio.file_id}{ext}"
            file_path = storage.save_file(file_data, filename, content_type=mime_type)
            
            # Transcribe
            # Note: For transcription, we might need a temp file or pass bytes if API supports it
            # AI Manager expects file path or bytes? Let's check ai_services.py.
            # It likely takes a file path. We might need to write a temp file for processing if it relies on local file.
            # But the storage abstraction returns a path or URL.
            # If AI manager needs a local file, we might need a temp one.
            # Let's check ai_services logic. 
            # If it accepts bytes, great. If not, we download to temp.
            
            # Assuming analyze_audio takes bytes or path. 
            # Since OpenAI/Gemini API often handles files, bytes are best.
            transcription = self.ai_manager.transcribe_audio(file_data) # Assuming this method exists and accepts bytes
            
            # ... (Rest of logic) ...
            self._process_and_store(
                update,
                content=transcription,
                content_type='audio',
                file_path=file_path,
                reply_message=message
            )
            
        except Exception as e:
            logger.error(f"Error handling audio: {e}")
            if 'message' in locals():
                asyncio.run(message.edit_text(f"‚ùå Error: {str(e)}"))

    async def handle_video(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle video files"""
        await self._run_async(self._handle_video_impl, update, context)

    def _handle_video_impl(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        try:
            message = asyncio.run(update.message.reply_text("üé• Processing video..."))
            
            video = update.message.video
            file = asyncio.run(context.bot.get_file(video.file_id))
            
            from io import BytesIO
            f = BytesIO()
            asyncio.run(file.download_to_memory(f))
            file_data = f.getvalue()
            
            timestamp = int(time.time())
            filename = f"video/{timestamp}_{video.file_id}.mp4"
            file_path = storage.save_file(file_data, filename, content_type=video.mime_type)
            
            # Helper to extract description
            description = update.message.caption or "Video entry"
            
            self._process_and_store(
                update,
                content=description,
                content_type='video',
                file_path=file_path,
                reply_message=message
            )
            
        except Exception as e:
             logger.error(f"Error handling video: {e}")
             if 'message' in locals():
                 asyncio.run(message.edit_text(f"‚ùå Error: {str(e)}"))
                 
    async def handle_animation(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle GIFs/Animations"""
        await self._run_async(self._handle_animation_impl, update, context)

    def _handle_animation_impl(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        try:
            message = asyncio.run(update.message.reply_text("üéûÔ∏è Processing GIF..."))
            
            animation = update.message.animation
            file = asyncio.run(context.bot.get_file(animation.file_id))
            
            from io import BytesIO
            f = BytesIO()
            asyncio.run(file.download_to_memory(f))
            file_data = f.getvalue()
            
            timestamp = int(time.time())
            filename = f"images/{timestamp}_{animation.file_id}.mp4" # Save as MP4
            file_path = storage.save_file(file_data, filename, content_type=animation.mime_type)
            
            description = "GIF Animation"
            
            self._process_and_store(
                update,
                content=description,
                content_type='image', # Treat as image/animation
                file_path=file_path,
                reply_message=message
            )
        except Exception as e:
            logger.error(f"Error handling animation: {e}")
            if 'message' in locals():
                asyncio.run(message.edit_text(f"‚ùå Error: {str(e)}"))


    # ... (handle_text remains similar but wrapped) ...
    async def handle_text(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        await self._run_async(self._handle_text_impl, update, context)

    def _handle_text_impl(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
         # ... existing text handling logic ...
         # For brevity, reusing the core logic. 
         # Since I am replacing the file, I must ensure I don't lose the logic.
         pass # I will need to read and copy the full logic if I replace the whole file. 
              # To be safe, I should use `replace_file_content` on specific blocks or write the whole file carefully.

    def _run_async(self, func, update, context):
        """Run a synchronous function in a separate thread"""
        loop = asyncio.get_event_loop()
        return loop.run_in_executor(None, func, update, context)

    def _process_and_store(self, update, content, content_type, file_path=None, reply_message=None):
        # ... logic to store to DB ...
        # I need to implement this or ensure it exists
        pass

    async def process_webhook_update(self, update_json):
        """Process an update received via webhook"""
        update = Update.de_json(update_json, self.application.bot)
        await self.application.process_update(update)

    def run_polling(self):
        """Run bot in polling mode"""
        print("ü§ñ NexusLog Telegram Bot is running in polling mode...")
        self.application.run_polling()

if __name__ == '__main__':
    bot = TelegramBot()
    bot.run_polling()


class TelegramBot:
    """Telegram bot for NexusLog"""
    
    def __init__(self):
        self.token = os.getenv('TELEGRAM_BOT_TOKEN')
        if not self.token:
            raise ValueError("TELEGRAM_BOT_TOKEN not set")
        
        self.ai_manager = AIServiceManager()
        self.category_manager = CategoryManager()
        
        try:
            self.sheets = SheetsIntegration()
            self.sheets.create_header_if_needed()
        except Exception as e:
            print(f"Google Sheets not configured: {e}")
            self.sheets = None
        
        # Initialize content extractor for URL/image/video processing
        self.content_extractor = get_content_extractor()
        
        self.app = Application.builder().token(self.token).build()
        self._setup_handlers()
    
    def _setup_handlers(self):
        """Setup message handlers"""
        self.app.add_handler(CommandHandler("start", self.start_command))
        self.app.add_handler(CommandHandler("help", self.help_command))
        
        # Message handlers
        self.app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_text))
        self.app.add_handler(MessageHandler(filters.PHOTO, self.handle_image))
        self.app.add_handler(MessageHandler(filters.ANIMATION, self.handle_animation))
        self.app.add_handler(MessageHandler(filters.VOICE | filters.AUDIO, self.handle_audio))
        self.app.add_handler(MessageHandler(filters.VIDEO, self.handle_video))
    
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /start command"""
        welcome_message = """
üß† Welcome to NexusLog!

I'm your AI-powered idea logger. Send me:
- üìù Text messages
- üñºÔ∏è Images
- üé§ Voice notes
- üé• Videos
- üîó Links

I'll process, categorize, and store everything for you!

Use /help to see all commands.
        """
        await update.message.reply_text(welcome_message)
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /help command"""
        help_text = """
üìö NexusLog Commands:

/start - Start the bot
/help - Show this help message

üí° How to use:
- Just send me any content!
- Add "content idea" to mark as content
- Specify output types: "blog", "youtube", "linkedin", "shorts", "reels"
- Example: "content idea for blog and youtube: How to build AI apps"

I'll automatically categorize and process everything! üöÄ
        """
        await update.message.reply_text(help_text)
    
    def _parse_input_metadata(self, text: str) -> Dict:
        """
        Parse input text for metadata hints
        Returns: {
            'is_content_idea': bool,
            'output_types': list,
            'clean_text': str
        }
        """
        text_lower = text.lower()
        
        # Check if it's a content idea
        is_content_idea = 'content idea' in text_lower or 'idea' in text_lower
        
        # Extract output types
        output_types = []
        if 'blog' in text_lower or 'article' in text_lower:
            output_types.append('blog')
        if 'youtube' in text_lower or 'video' in text_lower:
            output_types.append('youtube')
        if 'linkedin' in text_lower:
            output_types.append('linkedin')
        if 'shorts' in text_lower or 'reels' in text_lower or 'short' in text_lower:
            output_types.append('shorts')
        
        # If "all" is mentioned or no specific type, default to all
        if 'all' in text_lower or (is_content_idea and not output_types):
            output_types = ['blog', 'youtube', 'linkedin', 'shorts', 'reels']
        
        # Clean the text (remove metadata hints)
        clean_text = re.sub(r'\b(content idea|idea|for|blog|youtube|linkedin|shorts|reels|all)\b', '', text, flags=re.IGNORECASE)
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        
        return {
            'is_content_idea': is_content_idea,
            'output_types': output_types,
            'clean_text': clean_text if clean_text else text
        }
    
    def _ai_process_text(self, text: str) -> list:
        """
        Shared AI processing for text content (used by both text and voice handlers).
        Returns LIST of dicts, each with: processed_content, category, is_content_idea, title, processing_note, intent
        Supports multi-item messages (e.g., "Add X to todo and Y as content idea")
        """
        try:
            # AI-first processing: intent detection, spell correction, multi-item parsing
            ai_prompt = f"""You are NexusLog AI assistant. Analyze this user message and respond in JSON format only.

User message: "{text}"

IMPORTANT: The user may mention MULTIPLE DISTINCT ITEMS in one message. For example:
- "Add 'review PRs' to todo and 'API patterns' as content idea" = 2 items
- "Remember to call mom, also got an idea for AI blog post" = 2 items  
- "Met John today for lunch" = 1 item

Determine:
1. How many DISTINCT items/notes are in this message? Parse each separately.

2. For EACH item determine:
   - INTENT: "note" (info to save) or "instruction" (action to perform)
   - Category: "Content Ideas", "VibeCoding Projects", "Stock Trading", "To-Do", "To Learn" (subcategories: "Reading List", "Videos"), or "General Notes"
   - Is it a content idea for blog/youtube/social?
   - A SHORT TITLE (max 50 chars)
   - Cleaned/corrected content

Respond ONLY with valid JSON (no markdown, no explanation):
{{
  "items": [
    {{
      "intent": "note" or "instruction",
      "title": "<short 5-10 word title>",
      "processed_content": "<cleaned note OR action result>",
      "category": "<suggested category>",
      "is_content_idea": true/false,
      "processing_note": "<brief note about what you did>"
    }}
  ]
}}

If single item, return array with 1 element. If multiple items, return array with each item."""

            ai_response = self.ai_manager.process_message(ai_prompt)
            
            # Default single item
            default_item = {
                'processed_content': text,
                'category': 'General Notes',
                'is_content_idea': False,
                'title': text[:50] + '...' if len(text) > 50 else text,
                'processing_note': '',
                'intent': 'note'
            }
            
            if ai_response:
                try:
                    # Parse JSON from response (handle markdown code blocks)
                    json_str = ai_response
                    if '```json' in json_str:
                        json_str = json_str.split('```json')[1].split('```')[0]
                    elif '```' in json_str:
                        json_str = json_str.split('```')[1].split('```')[0]
                    
                    ai_result = json.loads(json_str.strip())
                    
                    # Handle new multi-item format
                    if 'items' in ai_result and isinstance(ai_result['items'], list):
                        items = []
                        for item in ai_result['items']:
                            items.append({
                                'processed_content': item.get('processed_content', text),
                                'category': item.get('category', 'General Notes'),
                                'is_content_idea': item.get('is_content_idea', False),
                                'title': item.get('title', default_item['title']),
                                'processing_note': item.get('processing_note', ''),
                                'intent': item.get('intent', 'note')
                            })
                        return items if items else [default_item]
                    
                    # Backward compatibility with old single-item format
                    return [{
                        'processed_content': ai_result.get('processed_content', text),
                        'category': ai_result.get('category', 'General Notes'),
                        'is_content_idea': ai_result.get('is_content_idea', False),
                        'title': ai_result.get('title', default_item['title']),
                        'processing_note': ai_result.get('processing_note', ''),
                        'intent': ai_result.get('intent', 'note')
                    }]
                    
                except json.JSONDecodeError:
                    logger.warning(f"Failed to parse AI JSON, using raw response")
                    default_item['processed_content'] = ai_response
            
            return [default_item]
            
        except Exception as e:
            logger.error(f"AI processing error: {e}")
            return [{
                'processed_content': text,
                'category': 'General Notes',
                'is_content_idea': False,
                'title': text[:50] + '...' if len(text) > 50 else text,
                'processing_note': f'AI processing failed: {str(e)[:50]}',
                'intent': 'note'
            }]
    
    def _unified_ai_process(self, extracted_content: Dict[str, Any]) -> list:
        """
        Unified AI processing for ANY input combination.
        Takes extracted content from ContentExtractor and determines:
        - User's intent (save, summarize, analyze, etc.)
        - How many entries to create
        - Category and content for each entry
        
        Args:
            extracted_content: Dict from ContentExtractor.extract_all_content()
        
        Returns: List of dicts with processed entries
        """
        try:
            # Build context from all extracted content
            context_parts = []
            
            # User's direct text/caption
            if extracted_content.get('text'):
                context_parts.append(f"USER MESSAGE: {extracted_content['text']}")
            
            # Voice transcription
            if extracted_content.get('transcription'):
                context_parts.append(f"VOICE NOTE (transcribed): {extracted_content['transcription']}")
            
            # YouTube content with timestamps
            for yt in extracted_content.get('youtube_content', []):
                timestamps_info = ""
                if yt.get('timestamps'):
                    top_timestamps = yt['timestamps'][:10]  # First 10 timestamps for reference
                    timestamps_info = "\n- Key timestamps: " + ", ".join(
                        [f"[{t['time']}] {t['text'][:30]}..." for t in top_timestamps]
                    )
                context_parts.append(f"""YOUTUBE VIDEO:
- Title: {yt.get('title', 'Unknown')}
- Channel: {yt.get('channel', 'Unknown')}
- Duration: {yt.get('duration_seconds', 0) // 60} minutes
- URL: {yt.get('url', '')}""")
            
            # Non-YouTube video platform content (Vimeo, Twitter, etc.)
            for vid in extracted_content.get('video_platform_content', []):
                context_parts.append(f"""VIDEO ({vid.get('platform', 'Unknown')}):
- Title: {vid.get('title', 'Unknown')}
- Duration: {vid.get('duration_seconds', 0) // 60} minutes
- URL: {vid.get('url', '')}""")
            
            # Generic URL content
            for url_data in extracted_content.get('url_content', []):
                context_parts.append(f"""WEB PAGE:
- URL: {url_data.get('url', '')}
- Title: {url_data.get('title', 'Unknown')}""")
            
            # Image analysis (from file upload)
            if extracted_content.get('image_analysis'):
                # For direct images, we just want a title/caption, not full OCR
                # But we pass the analysis in case it helps generate a Title
                context_parts.append(f"IMAGE: {extracted_content['image_analysis']}")
            
            # Image URL analyses (from image URLs in text)
            for img_analysis in extracted_content.get('image_url_analyses', []):
                context_parts.append(f"IMAGE FROM URL ANALYSIS: {img_analysis.get('analysis', '')}")
            
            # Reply context
            if extracted_content.get('reply_context'):
                ctx = extracted_content['reply_context']
                context_parts.append(f"REPLYING TO MESSAGE: {ctx.get('text', '[media content]')}")
            
            # Combine all context
            full_context = "\n\n".join(context_parts)
            
            if not full_context.strip():
                return [{
                    'processed_content': 'No content to process',
                    'category': 'General Notes',
                    'is_content_idea': False,
                    'title': 'Empty Input',
                    'processing_note': 'No content extracted',
                    'intent': 'note'
                }]
            
            # Enhanced AI prompt for Smart Logger
            ai_prompt = f"""You are NexusLog Smart Logger. Analyze the input and respond in JSON.

INPUT CONTENT:
{full_context}

INSTRUCTIONS:
1. **NO SUMMARIZATION**: Do not summarize articles, videos, or external content.
2. **Text/Voice Notes**: Correct grammar, spelling, and formatting ONLY. Retain the original message length, tone, and details.
3. **Media/Links**: detailed log entry with the Title and Metadata. Do not hallucinate content you don't see.
4. **Trading Journal**: If the input mentions "Trading Journal", "Trade", "Stock", or specific stock symbols with dates, identify as "Stock Trading".

CATEGORIES: "Content Ideas", "VibeCoding Projects", "Stock Trading", "To-Do", "To Learn" (subcategories: "Reading List", "Videos"), "General Notes"

Respond ONLY with valid JSON:
{{
  "items": [
    {{
      "intent": "note" | "trade_journal",
      "date": "M/D/YYYY",
      "stock_symbol": "SYMBOL",
      "title": "<Short descriptive title>",
      "processed_content": "<The corrected text OR metadata description>",
      "category": "<category>",
      "subcategory": "<subcategory (optional)>",
      "is_content_idea": true/false
    }}
  ]
}}"""

            ai_response = self.ai_manager.process_message(ai_prompt)
            
            # Default item
            default_item = {
                'processed_content': full_context[:500],
                'category': 'General Notes',
                'is_content_idea': False,
                'title': 'Untitled Entry',
                'processing_note': '',
                'intent': 'note'
            }
            
            if ai_response:
                try:
                    # Parse JSON from response
                    json_str = ai_response
                    if '```json' in json_str:
                        json_str = json_str.split('```json')[1].split('```')[0]
                    elif '```' in json_str:
                        json_str = json_str.split('```')[1].split('```')[0]
                    
                    ai_result = json.loads(json_str.strip())
                    
                    if 'items' in ai_result and isinstance(ai_result['items'], list):
                        items = []
                        for item in ai_result['items']:
                            items.append({
                                'processed_content': item.get('processed_content', default_item['processed_content']),
                                'category': item.get('category', 'General Notes'),
                                'is_content_idea': item.get('is_content_idea', False),
                                'title': item.get('title', default_item['title']),
                                'processing_note': item.get('processing_note', ''),
                                'intent': item.get('intent', 'note')
                            })
                        return items if items else [default_item]
                    
                    # Single item format
                    return [{
                        'processed_content': ai_result.get('processed_content', default_item['processed_content']),
                        'category': ai_result.get('category', 'General Notes'),
                        'is_content_idea': ai_result.get('is_content_idea', False),
                        'title': ai_result.get('title', default_item['title']),
                        'processing_note': ai_result.get('processing_note', ''),
                        'intent': ai_result.get('intent', 'note')
                    }]
                    
                except json.JSONDecodeError:
                    logger.warning("Failed to parse unified AI JSON response")
                    default_item['processed_content'] = ai_response[:1000]
            
            return [default_item]
            
        except Exception as e:
            logger.error(f"Unified AI processing error: {e}")
            return [{
                'processed_content': str(extracted_content)[:500],
                'category': 'General Notes',
                'is_content_idea': False,
                'title': 'Processing Error',
                'processing_note': f'Error: {str(e)[:100]}',
                'intent': 'note'
            }]
    
    async def handle_text(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        Unified text message handler.
        Extracts content from URLs (YouTube, web pages) and processes with AI.
        """
        text = update.message.text
        reply_to = update.message.reply_to_message
        
        # Send processing indicator
        await update.message.reply_text("üß† Processing with AI...")
        
        try:
            # Extract all content (URLs, YouTube, web pages)
            loop = asyncio.get_running_loop()
            extracted = await loop.run_in_executor(
                None, 
                lambda: self.content_extractor.extract_all_content(
                    text=text,
                    reply_to_message=reply_to
                )
            )
            
            # Show extraction notes if any
            if extracted.get('extraction_notes'):
                notes = "\n".join(f"‚Ä¢ {n}" for n in extracted['extraction_notes'][:3])
                await update.message.reply_text(f"üì• Extracted:\n{notes}")
            
            # Process with unified AI
            ai_items = await loop.run_in_executor(
                None,
                lambda: self._unified_ai_process(extracted)
            )
            
            # Parse metadata for output types
            metadata = self._parse_input_metadata(text)
            
            # Determine content type and extract source URL
            has_youtube = len(extracted.get('youtube_content', [])) > 0
            has_urls = len(extracted.get('url_content', [])) > 0
            content_type = 'youtube' if has_youtube else ('link' if has_urls else 'text')
            
            # Extract the original source URL for reliable frontend rendering
            source_url = None
            if has_youtube:
                source_url = extracted['youtube_content'][0].get('url', '')
            elif has_urls:
                source_url = extracted['url_content'][0].get('url', '')
            elif extracted.get('urls', {}).get('youtube'):
                source_url = extracted['urls']['youtube'][0]
            elif extracted.get('urls', {}).get('generic'):
                source_url = extracted['urls']['generic'][0]
            
            entry_ids = []
            
            # Process each AI item
            for ai_result in ai_items:
                entry_id = await self._process_and_store(
                    content=ai_result['processed_content'],
                    content_type=content_type if len(entry_ids) == 0 else 'text',
                    is_content_idea=metadata['is_content_idea'] or ai_result['is_content_idea'],
                    output_types=metadata['output_types'],
                    category_hint=ai_result['category'],
                    subcategory_hint=ai_result.get('subcategory'),
                    title=ai_result['title'],
                    source_url=source_url
                )
                entry_ids.append((entry_id, ai_result))
            
            # Build confirmation message
            if len(entry_ids) == 1:
                entry_id, ai_result = entry_ids[0]
                confirmation = f"‚úÖ Saved! Entry ID: {entry_id}\n"
                
                if ai_result['intent'] == "summary":
                    confirmation += "üìù Summary created\n"
                elif ai_result['intent'] == "analysis":
                    confirmation += "üîç Analysis complete\n"
                else:
                    confirmation += "üìù Saved as note\n"
                
                if content_type == 'youtube':
                    confirmation += "üé¨ YouTube content processed\n"
                elif content_type == 'link':
                    confirmation += "üîó Link content extracted\n"
                
                # Handle Trading Journal
                if ai_result.get('intent') == 'trade_journal':
                    date = ai_result.get('date')
                    stock = ai_result.get('stock_symbol')
                    if date and stock:
                        # Call Sheets Agent
                        # Assuming 'sheets' is available via app structure or we import it
                        # telegram_bot.py usually doesn't import app.py to avoid circular deps.
                        # But app.py imports telegram_bot potentially? No, app runs bot.
                        # We need to import SheetsIntegration here or pass it.
                        # Let's import singleton if possible or create new.
                        from sheets_integration import SheetsIntegration
                        try:
                            sheets = SheetsIntegration()
                            sheet_result = sheets.log_trade_journal(
                                date=date,
                                stock_symbol=stock,
                                commentary=ai_result['processed_content'], # Col L
                                lessons="" # Col M (Empty by default for now)
                            )
                            if sheet_result['success']:
                                confirmation += f"üìä Sheet Updated: {sheet_result['message']}\n"
                            else:
                                confirmation += f"‚ö†Ô∏è Sheet Error: {sheet_result['message']}\n"
                        except Exception as e:
                            confirmation += f"‚ö†Ô∏è Sheet Handling Failed: {str(e)}\n"
                    else:
                         confirmation += "‚ö†Ô∏è Trade detected but Date/Stock missing for Sheet.\n"

                if ai_result['category']:
                    confirmation += f"üìÅ Category: {ai_result['category']}\n"
                
                if ai_result['is_content_idea']:
                    confirmation += "üí° Marked as content idea\n"
                
                if ai_result['processing_note']:
                    confirmation += f"\nüß† AI: {ai_result['processing_note'][:150]}"
                
                preview = ai_result['processed_content'][:2000] + "..." if len(ai_result['processed_content']) > 2000 else ai_result['processed_content']
                confirmation += f"\n\nüìã Content:\n{preview}"
            else:
                confirmation = f"‚úÖ Created {len(entry_ids)} entries!\n\n"
                for i, (entry_id, ai_result) in enumerate(entry_ids, 1):
                    confirmation += f"**{i}. {ai_result['title'][:40]}**\n"
                    confirmation += f"   üìÅ {ai_result['category']}"
                    if ai_result['is_content_idea']:
                        confirmation += " üí°"
                    confirmation += f" (ID: {entry_id})\n\n"
            
            await update.message.reply_text(confirmation)
            
        except Exception as e:
            logger.error(f"Unified text processing failed: {e}")
            # Fallback: save as-is
            metadata = self._parse_input_metadata(text)
            entry_id = await self._process_and_store(
                content=text,
                content_type='text',
                is_content_idea=metadata['is_content_idea'],
                output_types=metadata['output_types']
            )
            await update.message.reply_text(f"‚úÖ Saved (basic mode). Entry ID: {entry_id}")
    
    async def handle_image(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        Unified image handler with vision analysis.
        Uses Gemini Vision for full image understanding, not just OCR.
        """
        photo = update.message.photo[-1]  # Get highest resolution
        file = await photo.get_file()
        
        # Download file bytes
        from io import BytesIO
        f = BytesIO()
        await file.download_to_memory(f)
        file_data = f.getvalue()
        
        caption = update.message.caption or ""
        reply_to = update.message.reply_to_message
        
        await update.message.reply_text("üîç Analyzing image with AI vision...")
        
        # 1. Save to temp file for AI processing (AI services require local path)
        import tempfile
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp:
            temp.write(file_data)
            temp_path = temp.name
            
        # 2. Upload to persistent storage (Local or Blob)
        timestamp = int(time.time())
        filename = f"images/{timestamp}_{photo.file_id}.jpg"
        persistent_path = storage.save_file(file_data, filename, content_type='image/jpeg')
        
        try:
            # Extract content with image analysis using temp path
            loop = asyncio.get_running_loop()
            extracted = await loop.run_in_executor(
                None,
                lambda: self.content_extractor.extract_all_content(
                    text=caption,
                    image_path=temp_path,
                    reply_to_message=reply_to
                )
            )
            
            # Process with unified AI
            ai_items = await loop.run_in_executor(
                None,
                lambda: self._unified_ai_process(extracted)
            )
            
            metadata = self._parse_input_metadata(caption) if caption else {'is_content_idea': False, 'output_types': []}
            
            entry_ids = []
            for ai_result in ai_items:
                entry_id = await self._process_and_store(
                    content=ai_result['processed_content'],
                    content_type='image' if len(entry_ids) == 0 else 'text',
                    file_path=persistent_path if len(entry_ids) == 0 else None,
                    is_content_idea=metadata.get('is_content_idea', False) or ai_result['is_content_idea'],
                    output_types=metadata.get('output_types', []),
                    category_hint=ai_result['category'],
                    subcategory_hint=ai_result.get('subcategory'),
                    title=ai_result['title']
                )
                entry_ids.append((entry_id, ai_result))
            
            # Build confirmation
            if len(entry_ids) == 1:
                entry_id, ai_result = entry_ids[0]
                confirmation = f"‚úÖ Image analyzed! Entry ID: {entry_id}\n"
                confirmation += f"üìÅ Category: {ai_result['category']}\n"
                
                if ai_result['is_content_idea']:
                    confirmation += "üí° Marked as content idea\n"
                
                preview = ai_result['processed_content'][:400] + "..." if len(ai_result['processed_content']) > 400 else ai_result['processed_content']
                confirmation += f"\nüìã Analysis:\n{preview}"
            else:
                confirmation = f"‚úÖ Created {len(entry_ids)} entries from image!\n\n"
                for i, (entry_id, ai_result) in enumerate(entry_ids, 1):
                    confirmation += f"**{i}. {ai_result['title'][:40]}** (ID: {entry_id})\n"
            
            await update.message.reply_text(confirmation)
            
        except Exception as e:
            logger.error(f"Image processing failed: {e}")
            # Fallback: save with basic OCR using temp path
            try:
                extracted_text = self.ai_manager.ocr_image(temp_path)
            except:
                extracted_text = "OCR Failed"
                
            entry_id = await self._process_and_store(
                content=f"{caption}\n\nOCR: {extracted_text}",
                content_type='image',
                file_path=persistent_path
            )
            await update.message.reply_text(f"‚úÖ Image saved (basic OCR). Entry ID: {entry_id}")
            
        finally:
            # Cleanup temp file
            if os.path.exists(temp_path):
                os.unlink(temp_path)
    
    async def handle_animation(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        Handle GIF/animation messages.
        Telegram sends GIFs as MPEG4 animations. We save them and process like images.
        """
        animation = update.message.animation
        file = await animation.get_file()
        
        # Download file bytes
        from io import BytesIO
        f = BytesIO()
        await file.download_to_memory(f)
        file_data = f.getvalue()
        
        # Determine extension
        mime_type = animation.mime_type or ''
        ext = '.gif' if 'gif' in mime_type else '.mp4'
        
        # 1. Save to temp file for AI
        import tempfile
        with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as temp:
            temp.write(file_data)
            temp_path = temp.name
            
        # 2. Upload to persistent storage
        timestamp = int(time.time())
        filename = f"images/{timestamp}_{animation.file_id}{ext}"
        persistent_path = storage.save_file(file_data, filename, content_type=mime_type)
        
        caption = update.message.caption or ""
        reply_to = update.message.reply_to_message
        
        await update.message.reply_text("üéûÔ∏è Processing GIF/animation...")
        
        try:
            # Process with AI vision (same as images)
            loop = asyncio.get_running_loop()
            extracted = await loop.run_in_executor(
                None,
                lambda: self.content_extractor.extract_all_content(
                    text=caption,
                    image_path=temp_path,
                    reply_to_message=reply_to
                )
            )
            
            ai_items = await loop.run_in_executor(
                None,
                lambda: self._unified_ai_process(extracted)
            )
            
            metadata = self._parse_input_metadata(caption) if caption else {'is_content_idea': False, 'output_types': []}
            
            entry_ids = []
            for ai_result in ai_items:
                entry_id = await self._process_and_store(
                    content=ai_result['processed_content'],
                    content_type='image' if len(entry_ids) == 0 else 'text',
                    file_path=persistent_path if len(entry_ids) == 0 else None,
                    is_content_idea=metadata.get('is_content_idea', False) or ai_result['is_content_idea'],
                    output_types=metadata.get('output_types', []),
                    category_hint=ai_result['category'],
                    subcategory_hint=ai_result.get('subcategory'),
                    title=ai_result['title']
                )
                entry_ids.append((entry_id, ai_result))
            
            # Build confirmation
            if len(entry_ids) == 1:
                entry_id, ai_result = entry_ids[0]
                confirmation = f"‚úÖ GIF analyzed! Entry ID: {entry_id}\n"
                confirmation += f"üìÅ Category: {ai_result['category']}\n"
                preview = ai_result['processed_content'][:400] + "..." if len(ai_result['processed_content']) > 400 else ai_result['processed_content']
                confirmation += f"\nüìã Analysis:\n{preview}"
            else:
                confirmation = f"‚úÖ Created {len(entry_ids)} entries from GIF!\n\n"
                for i, (entry_id, ai_result) in enumerate(entry_ids, 1):
                    confirmation += f"**{i}. {ai_result['title'][:40]}** (ID: {entry_id})\n"
            
            await update.message.reply_text(confirmation)
            
        except Exception as e:
            logger.error(f"GIF processing failed: {e}")
            entry_id = await self._process_and_store(
                content=caption or "GIF/Animation uploaded",
                content_type='image',
                file_path=persistent_path
            )
            await update.message.reply_text(f"‚úÖ GIF saved (basic). Entry ID: {entry_id}")
            
        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)
    
    async def handle_audio(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        Unified voice/audio handler.
        Transcribes audio, extracts URLs mentioned in speech, and processes with unified AI.
        """
        audio = update.message.voice or update.message.audio
        file = await audio.get_file()
        
        # Download file bytes
        from io import BytesIO
        f = BytesIO()
        await file.download_to_memory(f)
        file_data = f.getvalue()
        
        # 1. Save to temp file for AI
        import tempfile
        with tempfile.NamedTemporaryFile(suffix='.ogg', delete=False) as temp:
            temp.write(file_data)
            temp_path = temp.name
            
        # 2. Upload to persistent storage
        # Note: audio often has no name, we use file_id
        timestamp = int(time.time())
        filename = f"audio/{timestamp}_{audio.file_id}.ogg"
        persistent_path = storage.save_file(file_data, filename, content_type='audio/ogg')
        
        reply_to = update.message.reply_to_message
        
        # Transcribe
        await update.message.reply_text("üéôÔ∏è Transcribing voice note...")
        transcription = self.ai_manager.transcribe_audio(temp_path)
        
        if not transcription:
            await update.message.reply_text("‚ùå Failed to transcribe voice note")
            # Cleanup
            if os.path.exists(temp_path):
                os.unlink(temp_path)
            return
        
        await update.message.reply_text("üß† Processing with AI...")
        
        try:
            loop = asyncio.get_running_loop()
            # Extract content (URLs mentioned in voice note, reply context)
            extracted = await loop.run_in_executor(
                None,
                lambda: self.content_extractor.extract_all_content(
                    transcription=transcription,
                    reply_to_message=reply_to
                )
            )
            
            # Show extraction notes if any URLs were found
            if extracted.get('extraction_notes'):
                notes = "\n".join(f"‚Ä¢ {n}" for n in extracted['extraction_notes'][:3])
                await update.message.reply_text(f"üì• Extracted:\n{notes}")
            
            # Process with unified AI
            ai_items = await loop.run_in_executor(
                None,
                lambda: self._unified_ai_process(extracted)
            )
            
            metadata = self._parse_input_metadata(transcription)
            
            entry_ids = []
            for ai_result in ai_items:
                entry_id = await self._process_and_store(
                    content=ai_result['processed_content'],
                    content_type='audio' if len(entry_ids) == 0 else 'text',
                    file_path=persistent_path if len(entry_ids) == 0 else None,
                    is_content_idea=metadata['is_content_idea'] or ai_result['is_content_idea'],
                    output_types=metadata['output_types'],
                    category_hint=ai_result['category'],
                    subcategory_hint=ai_result.get('subcategory'),
                    title=ai_result['title']
                )
                entry_ids.append((entry_id, ai_result))
            
            # Build confirmation
            if len(entry_ids) == 1:
                entry_id, ai_result = entry_ids[0]
                confirmation = f"‚úÖ Voice note processed! Entry ID: {entry_id}\n"
                confirmation += f"üìÅ Category: {ai_result['category']}\n"
                
                if ai_result['is_content_idea']:
                    confirmation += "üí° Marked as content idea\n"
                
                preview = ai_result['processed_content'][:250] + "..." if len(ai_result['processed_content']) > 250 else ai_result['processed_content']
                confirmation += f"\nüìã Content:\n{preview}"
            else:
                confirmation = f"‚úÖ Created {len(entry_ids)} entries from voice note!\n\n"
                for i, (entry_id, ai_result) in enumerate(entry_ids, 1):
                    confirmation += f"**{i}. {ai_result['title'][:40]}** (ID: {entry_id})\n"
            
            await update.message.reply_text(confirmation)
            
            # TTS confirmation
            try:
                first_content = ai_items[0]['processed_content'] if ai_items else transcription
                tts_text = f"Processed: {first_content[:150]}"
                audio_data = self.ai_manager.text_to_speech(tts_text)
                if audio_data:
                    await update.message.reply_voice(audio_data, caption="üéôÔ∏è Confirmation")
            except Exception as e:
                logger.warning(f"TTS failed: {e}")
                
        except Exception as e:
            logger.error(f"Voice processing failed: {e}")
            # Fallback: save transcription as-is
            entry_id = await self._process_and_store(
                content=transcription,
                content_type='audio',
                file_path=persistent_path
            )
            await update.message.reply_text(f"‚úÖ Voice note saved (basic). Entry ID: {entry_id}")
            
        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)
    
    async def handle_video(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        Unified video handler.
        Transcribes video audio and processes with unified AI.
        """
        video = update.message.video
        file = await video.get_file()
        
        # Download bytes
        from io import BytesIO
        f = BytesIO()
        await file.download_to_memory(f)
        file_data = f.getvalue()
        
        # 1. Save to temp file for AI
        import tempfile
        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp:
            temp.write(file_data)
            temp_path = temp.name
            
        # 2. Upload to persistent storage
        timestamp = int(time.time())
        filename = f"video/{timestamp}_{video.file_id}.mp4"
        persistent_path = storage.save_file(file_data, filename, content_type='video/mp4')
        
        caption = update.message.caption or ""
        reply_to = update.message.reply_to_message
        
        await update.message.reply_text("üé¨ Processing video...")
        
        try:
            loop = asyncio.get_running_loop()
            # Transcribe video audio using temp path
            transcription = await loop.run_in_executor(
                None,
                self.ai_manager.transcribe_video,
                temp_path
            )
            
            # Extract content
            extracted = await loop.run_in_executor(
                None,
                lambda: self.content_extractor.extract_all_content(
                    text=caption,
                    transcription=transcription,
                    reply_to_message=reply_to
                )
            )
            
            # Process with unified AI
            ai_items = await loop.run_in_executor(
                None,
                lambda: self._unified_ai_process(extracted)
            )
            
            metadata = self._parse_input_metadata(caption or transcription)
            
            entry_ids = []
            for ai_result in ai_items:
                entry_id = await self._process_and_store(
                    content=ai_result['processed_content'],
                    content_type='video' if len(entry_ids) == 0 else 'text',
                    file_path=persistent_path if len(entry_ids) == 0 else None,
                    is_content_idea=metadata['is_content_idea'] or ai_result['is_content_idea'],
                    output_types=metadata['output_types'],
                    category_hint=ai_result['category'],
                    subcategory_hint=ai_result.get('subcategory'),
                    title=ai_result['title']
                )
                entry_ids.append((entry_id, ai_result))
            
            # Build confirmation
            if len(entry_ids) == 1:
                entry_id, ai_result = entry_ids[0]
                confirmation = f"‚úÖ Video processed! Entry ID: {entry_id}\n"
                confirmation += f"üìÅ Category: {ai_result['category']}\n"
                preview = ai_result['processed_content'][:250] + "..." if len(ai_result['processed_content']) > 250 else ai_result['processed_content']
                confirmation += f"\nüìã Content:\n{preview}"
            else:
                confirmation = f"‚úÖ Created {len(entry_ids)} entries from video!\n\n"
                for i, (entry_id, ai_result) in enumerate(entry_ids, 1):
                    confirmation += f"**{i}. {ai_result['title'][:40]}** (ID: {entry_id})\n"
            
            await update.message.reply_text(confirmation)
            
        except Exception as e:
            logger.error(f"Video processing failed: {e}")
            entry_id = await self._process_and_store(
                content=caption or "Video uploaded",
                content_type='video',
                file_path=persistent_path
            )
            await update.message.reply_text(f"‚úÖ Video saved (basic). Entry ID: {entry_id}")
            
        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)
    
    async def _process_and_store(
        self,
        content: str,
        content_type: str,
        file_path: str = None,
        is_content_idea: bool = False,
        output_types: List[str] = None,

        category_hint: str = None,
        subcategory_hint: str = None,
        title: str = None,
        source_url: str = None
    ) -> int:
        """Process content and store in database"""
        session = get_session()
        try:
            # Get category suggestion - prefer AI hint if provided
            if category_hint:
                # Use the AI-suggested category name to find ID
                category_info = self.category_manager.get_category_by_name(category_hint)
                # Manually handle subcategory if hint provided
                if subcategory_hint and category_info.get('category_id'):
                    parent_id = category_info['category_id']
                    sub_cat = session.query(Category).filter(
                        Category.name == subcategory_hint, 
                        Category.parent_id == parent_id
                    ).first()
                    if not sub_cat:
                        # Auto-create subcategory
                        sub_cat = Category(
                            name=subcategory_hint,
                            parent_id=parent_id,
                            description="Auto-created by AI"
                        )
                        session.add(sub_cat)
                        session.flush()
                    category_info['subcategory_id'] = sub_cat.id

            else:
                category_info = self.category_manager.suggest_category(content)
            
            # Create entry
            entry = Entry(
                raw_content=content,
                processed_content=content,  # Already processed by AI
                content_type=content_type,
                file_path=file_path,
                category_id=category_info.get('category_id'),
                subcategory_id=category_info.get('subcategory_id'),
                source='telegram',
                entry_metadata={
                    'is_content_idea': is_content_idea or category_info.get('is_content_idea', False),
                    'output_types': output_types or [],
                    'source_url': source_url
                }
            )
            session.add(entry)
            session.flush()
            
            # If it's a content idea, create ContentIdea entry
            if is_content_idea or category_info.get('is_content_idea'):
                ai_prompt = self.ai_manager.generate_content_prompt(content)
                
                # Generate title if not provided
                idea_title = title or (content[:50] + '...' if len(content) > 50 else content)
                
                content_idea = ContentIdea(
                    entry_id=entry.id,
                    title=idea_title,
                    idea_description=content,
                    ai_prompt=ai_prompt,
                    output_types=output_types or ['blog', 'youtube', 'linkedin', 'shorts', 'reels'],
                    status='idea'
                )
                session.add(content_idea)
                session.flush()
                
                # Sync to Google Sheets
                if self.sheets:
                    try:
                        self.sheets.append_content_idea(
                            content,
                            ai_prompt,
                            output_types or []
                        )
                    except Exception as e:
                        print(f"Error syncing to Google Sheets: {e}")
            
            session.commit()
            return entry.id
        
        finally:
            session.close()
    
    async def process_webhook_update(self, update_json):
        """Process an update received via webhook"""
        update = Update.de_json(update_json, self.app.bot)
        await self.app.process_update(update)

    def run(self):
        """Run the bot in polling mode (default)"""
        print("NexusLog Telegram Bot is running...")
        
        # Heartbeat loop in background
        import threading
        def heartbeat():
            while True:
                try:
                    with open('bot_heartbeat.txt', 'w') as f:
                        f.write(str(time.time()))
                except Exception as e:
                    logger.error(f"Heartbeat failed: {e}")
                time.sleep(60)
        
        threading.Thread(target=heartbeat, daemon=True).start()
        
        self.app.run_polling()
    
    def set_webhook(self, webhook_url: str):
        """Set webhook for production"""
        # Note: python-telegram-bot's application.run_webhook is a blocking call that starts a server.
        # We just want to configuring the webhook url on Telegram servers.
        # But actually, we don't even need this method if we set it manually or via a script.
        # kept for reference.
        pass


if __name__ == "__main__":
    bot = TelegramBot()
    bot.run()
